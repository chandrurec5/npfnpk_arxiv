\section{Broader Impact}
Deep neural networks are still widely regarded as blackboxes. The standard and accepted view on the inner workings of  deep neural networks is the `layer-by-layer' viewpoint:  as the input progresses through the hidden layers, features at different levels of abstractions are learnt. This paper deviates from the standard `layer-by-layer' viewpoint, in that, it breaks down the deep neural network blackbox into its constituent paths: different set of paths get fired for different inputs, and the output is the summation of the contribution from individual paths. This makes the inner workings of deep neural networks interpretable, i.e., each input is remembered in terms of the active sub-network of the paths that get `fired' for that input, and learning via gradient descent amounts to `rewiring' of the paths. The paper also analytically connects this sub-network and path based view to the recent kernel based interpretation of deep neural networks, and furthers the understanding of feature learning in deep neural networks. We believe that these better insights into the working of DNNs  can potentially lead to foundational algorithmic development in the future.

