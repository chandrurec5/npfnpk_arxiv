{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gast==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import *\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import re\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = y_train.copy()\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getEig(g_mat):\n",
    "    eig_vals = np.linalg.eig(g_mat)\n",
    "    eig_vals = np.real(eig_vals[0])\n",
    "    return eig_vals\n",
    "\n",
    "def getRandomIndices(max_lim, num_ind):\n",
    "    all_indices  = np.arange(0, max_lim)\n",
    "    np.random.shuffle(np.arange(0, max_lim))\n",
    "    return all_indices[: num_ind]\n",
    "\n",
    "def getUniqueLabelExamples(x_train, y_train, num_class, num_each_class):\n",
    "    x_batch = x_train[:num_each_class * num_class,:].copy()\n",
    "    y_batch = y_train[:num_each_class * num_class,:].copy()\n",
    "\n",
    "    for ind in range(10):\n",
    "        x_temp = x_train[(y_train1 == ind), :]\n",
    "        y_temp = y_train[(y_train1 == ind), :]\n",
    "        max_lim = x_temp.shape[0]\n",
    "        indices = getRandomIndices(max_lim, num_each_class)\n",
    "        x_batch[ind*num_each_class: (ind+1)*num_each_class, :] = x_temp[indices, :]\n",
    "        y_batch[ind*num_each_class: (ind+1)*num_each_class, : ] = y_temp[indices, :]\n",
    "\n",
    "    return x_batch, y_batch\n",
    "\n",
    "sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "def getNetwork1Layers(model):\n",
    "    pattern = re.compile(\"^R[0-9]*$\")\n",
    "    layer_list  = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if pattern.match(layer.name):\n",
    "            layer_list.append(layer)\n",
    "\n",
    "    return layer_list\n",
    "\n",
    "def getNetwork2Layers(model):\n",
    "    pattern = re.compile(\"^G[0-9]*$\")\n",
    "    layer_list  = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if pattern.match(layer.name):\n",
    "            layer_list.append(layer)\n",
    "\n",
    "    return layer_list\n",
    "    \n",
    "def freezeWeights(layers):\n",
    "    for layer in layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def getNetwork1TrainableWts(model):\n",
    "    layer_list = getNetwork1Layers(model)\n",
    "    wts = []\n",
    "    for layer in layer_list:\n",
    "        wts.append((layer.trainable_weights + layer.non_trainable_weights)[0])\n",
    "\n",
    "    return wts\n",
    "\n",
    "def getNetwork2TrainableWts(model):\n",
    "    layer_list = getNetwork2Layers(model)\n",
    "    wts = []\n",
    "    for layer in layer_list:\n",
    "        wts.append((layer.trainable_weights + layer.non_trainable_weights)[0])\n",
    "\n",
    "    return wts\n",
    "\n",
    "def getNTK(model, x_batch, wts, epoch_i):\n",
    "    if epoch_i == 0:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "    gradients = K.gradients(model.output, wts)\n",
    "    Phi_E = None\n",
    "    for i in (range(x_batch.shape[0])):\n",
    "        grad = sess.run(gradients, feed_dict={model.input:x_batch[i:i+1, :]})\n",
    "        row_grad = []\n",
    "        for grad_layer in grad:\n",
    "            row_grad += grad_layer.flatten().tolist()\n",
    "\n",
    "        if Phi_E is None:\n",
    "            Phi_E = np.zeros((x_batch.shape[0], len(row_grad)))\n",
    "\n",
    "        Phi_E[i, :] = row_grad\n",
    "\n",
    "    return np.dot(Phi_E, Phi_E.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, beta = 0.1, 4\n",
    "class SoftGate(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftGate, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SoftGate, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        activation = (1 + eps)*K.sigmoid(beta*x)\n",
    "        return activation\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def getGalu(depth, width):\n",
    "    inputs = Input(shape = (784, ))\n",
    "\n",
    "    R1 = Dense(units = width, activation = 'linear', name = \"R1\")(inputs)\n",
    "    R1A = Activation('relu')(R1)\n",
    "    A1 = SoftGate()(R1)\n",
    "\n",
    "    G1 = Dense(units = width, activation = 'linear',  name = \"G1\")(inputs)\n",
    "    G1A = Multiply(name = \"G1A\")([G1, A1])\n",
    "\n",
    "    for i in range(depth - 2):\n",
    "        R1 = Dense(units = width, activation = 'linear',name = \"R\"+str(i+2))(R1A)\n",
    "        R1A = Activation('relu')(R1)\n",
    "        A1 = SoftGate()(R1)\n",
    "\n",
    "        G1 = Dense(units = width, activation = 'linear', name = \"G\"+str(i+2))(G1A)\n",
    "        G1A = Multiply(name = \"G\"+str(i+2)+\"A\")([G1, A1])\n",
    "\n",
    "    outputs = Dense(units = 10, activation = \"softmax\", name = \"G\"+str(depth))(G1A)\n",
    "    model = keras.Model(inputs = inputs, outputs = outputs, name = 'galu_model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, width = 6, 128\n",
    "lr = 1e-2\n",
    "loss = keras.losses.categorical_crossentropy\n",
    "opt = keras.optimizers.SGD\n",
    "batch_size = 32\n",
    "num_exp = 5\n",
    "num_epochs = 60\n",
    "\n",
    "history_galu = {'acc':[], 'val_acc':[], 'loss': [], 'val_loss': [], \n",
    "                'norm_value': [], 'norm_gate': [], \n",
    "                'trace_value': [], 'trace_gate': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = getUniqueLabelExamples(x_train, y_train, 10, 20)\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train Galu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_i in range(num_exp):\n",
    "    print(\"_____________EXP:{}____________\".format(exp_i+1))\n",
    "    model_galu = getGalu(depth, width)\n",
    "    model_galu.compile(loss = loss, optimizer = opt(lr), metrics = ['acc'])\n",
    "    acc_temp = []\n",
    "    val_acc_temp = []\n",
    "    trace_temp_value = []\n",
    "    trace_temp_gate = []\n",
    "    norm_temp_value = []\n",
    "    norm_temp_gate = []\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        if epoch_i % 5 == 0:\n",
    "            wts = getNetwork2TrainableWts(model_galu)\n",
    "            K_t = getNTK(model_galu, x_batch, wts, epoch_i)\n",
    "            K_t_flatten = K_t.flatten()\n",
    "\n",
    "            trace_temp_value.append(np.sum(np.diagonal(K_t)))\n",
    "            norm_temp_value.append(np.linalg.norm(K_t_flatten))\n",
    "\n",
    "            wts = getNetwork1TrainableWts(model_galu)\n",
    "            K_t = getNTK(model_galu, x_batch, wts, epoch_i)\n",
    "            K_t_flatten = K_t.flatten()\n",
    "\n",
    "            trace_temp_gate.append(np.sum(np.diagonal(K_t)))\n",
    "            norm_temp_gate.append(np.linalg.norm(K_t_flatten))\n",
    "\n",
    "        history = model_galu.fit(x_train, y_train, validation_data = (x_test, y_test), verbose = 0,\n",
    "                             batch_size=batch_size, epochs= 1)\n",
    "        \n",
    "        acc_temp.append(history.history['acc'][0])\n",
    "        val_acc_temp.append(history.history['val_acc'][0])\n",
    "    \n",
    "    history_galu['acc'].append(acc_temp)\n",
    "    history_galu['val_acc'].append(val_acc_temp)\n",
    "    history_galu['trace_value'].append(trace_temp_value)\n",
    "    history_galu['trace_gate'].append(trace_temp_gate)\n",
    "    \n",
    "    history_galu['norm_value'].append(norm_temp_value)\n",
    "    history_galu['norm_gate'].append(norm_temp_gate)\n",
    "\n",
    "    print(\"GaLU: MAX ACC = {:.4f}, MAX VAL ACC = {:.4f}\".format(np.max(history.history['acc']), \n",
    "                                                        np.max(history.history['val_acc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GaLU: max_acc = {:.4f}, mean_max_val_acc = {:.4f}, std_max_val_acc = {:.4f}\".format(\n",
    "                                                    np.mean(np.max(history_galu['acc'], axis = 1)), \n",
    "                                                    np.mean(np.max(history_galu['val_acc'], axis = 1)),\n",
    "                                                    np.std(np.max(history_galu['val_acc'], axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_value = np.mean(history_galu['trace_value'], axis = 0)\n",
    "trace_gate = np.mean(history_galu['trace_gate'], axis = 0)\n",
    "norm_value = np.mean(history_galu['norm_value'], axis = 0)\n",
    "norm_gate = np.mean(history_galu['norm_gate'], axis = 0)\n",
    "\n",
    "plt.plot(norm_value, '--', label = 'norm_value')\n",
    "plt.plot(norm_gate, '--', label = 'norm_gate')\n",
    "plt.plot(trace_value, label = 'trace_value')\n",
    "plt.plot(trace_gate, label = 'trace_gate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
